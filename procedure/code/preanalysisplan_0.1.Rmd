---
title: "Chakraborty (2021) Reproduction Study"
author: "Samuel Barnard"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs") })
nocite: '@*'
---

Version 1.0 \| First Created March 10, 2025 \| Updated April 8, 2025

# Abstract

Chakraborty (2021) investigates the relationships between COVID-19 incidence rates and several demographic characteristics of people with disabilities by county in the continental United States. The aim of the study is to investigate whether people with disabilities (PwDs) face disproportionate challenges due to COVID-19.

Continued, from **"Reproduction of Chakraborty 2021: An intracategorical analysis of COVID-19 and people with disabilities"** (Holler et al.):
To do so, Chakraborty examines the statistical relationship between county incidence rates of COVID-19 cases and county-level percentages of people with disabilities and different socio-demographic characteristics.
Specifically, Chakraborty tests county-level bivariate correlations between COVID-19 incidence against the percentage of disability as one hypothesis, and tests correlation between COVID-19 incidence and percentage of people with disabilities in 18 different socio-demographic categories of race, ethnicity, poverty status, age, and biological sex.
Chakraborty then re-tests for the same county-level associations while controlling for spatial dependence.
Spatial dependence is controlled by constructing generalized estimating equation (GEE) models using a combination of state and spatial clusters of COVID-19 incidence as to define the GEE clusters.
One GEE model is constructed for each of the four types of socio-demographic category: race, ethnicity, age, and biological sex.
Chakraborty (2021) finds significant positive relationships between COVID-19 rates and socially vulnerable demographic categories of race, ethnicity, poverty status, age, and biological sex.

# Study Design

This study is a reproduction, with the goal of examining Chakraborty's study design and its impact particularly in public policy as well as in fields such as research and education. This reproduction will attempt to reproduce the original study's results.

This will include the map of county level distribution of COVID-19 incidence rates (Fig. 1), the summary statistics for disability and socio-demographic variables and bivariate correlations with county-level COVID-19 incidence rate (Table 1), and the GEE models for predicting COVID-19 county-level incidence rate (Table 2).
A successful reproduction should be able to generate identical results as published by Chakraborty (2021).

Chakraborty, J.
2021.
Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S.
*Disability and Health Journal* 14:1-5.
<https://doi.org/10.1016/j.dhjo.2020.101007>

# Study data

## [Study metadata](data/metadata/)

## ACS Socio-demographic data

The American Community Survey (ACS) five-year estimate (2014-2018) variables used in the study are outlined in the table below.
Details on ACS data collection can be found at <https://www.census.gov/topics/health/disability/guidance/data-collection-acs.html> and details on sampling methods and accuracy can be found at <https://www.census.gov/programs-surveys/acs/technical-documentation/code-lists.html>.

| Variable Name in Study | ACS Variable name |
|:----------------------------------:|:----------------------------------:|
| percent of total civilian non-institutionalized population with a disability | S1810_C03_001E |
| **Race** |  |
| percent w disability: White alone | S1810_C03_004E |
| percent w disability: Black alone | S1810_C03_005E |
| percent w disability: Native American | S1810_C03_006E |
| percent w disability: Asian alone | S1810_C03_007E |
| percent w disability: Other race | S1810_C03_009E |
| **Ethnicity** |  |
| percent w disability: Non-Hispanic White | S1810_C03_0011E |
| percent w disability: Hispanic | S1810_C03_012E |
| percent w disability: Non-Hispanic non-White | (S1810_C02_001E - S1810_C02_011E - S1810_C02_012E) / (S1810_C01_001E - S1810_C01_011E - S1810_C01_012E) \* 100 |
| percent w disability: Other race | S1810_C03_009E |
| **Poverty** |  |
| percent w disability: Below poverty level | (C18130_004E + C18130_011E + C18130_018E) / C18130_001E \* 100 |
| percent w disability: Above poverty level | (C18130_005E + C18130_012E + C18130_019E) / C18130_001E \* 100 |
| **Age** |  |
| percent w disability: 5-17 | S1810_C03_014E |
| percent w disability: 18-34 | S1810_C03_015E |
| percent w disability: 35-64 | S1810_C03_016E |
| percent w disability: 65-74 | S1810_C03_017E |
| percent w disability: 75+ | S1810_C03_018E |
| **Biological sex** |  |
| percent w disability: male | S1810_C03_001E |
| percent w disability: female | S1810_C03_003E |

: Disability Subgroup Variables

American Community Survey (ACS) data for sociodemographic subcategories of people with disabilities can be accessed by using the `tidycensus` package to query the Census API. This requires an API key which can be acquired at [api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html).

## COVID-19 data

Data on COVID-19 cases from the Johns Hopkins University dashboard have been provided directly with the research compendium because the data is no longer available online in the state in which it was downloaded on August 1, 2020.
The dashboard and cumulative counts of COVID-19 cases and deaths were continually updated, so an exact reproduction required communication with the original author, Jayajit Chakraborty, for assistance with provision of data from August 1, 2020.
The data includes an estimate of the total population (`POP_ESTIMA`) and confirmed COVID-19 cases (`Confirmed`).
The COVID-19 case data expresses cumulative count of reported COVID-19 from 1/22/2020 to 8/1/2020.
Although metadata for this particular resource is no longer available from the original source, one can reasonably assume that the total population estimate was based on the 2014-2018 5-year ACS estimate, as the 2019 estimates data had not been released yet.

Versions of the data can be found at the John Hopkins CCSE COVID-19 Data Repository (<https://github.com/CSSEGISandData/COVID-19>).
However, archived data only provides summaries at the national scale.
We received the COVID-19 case data through 8/1/2020 at the county level from the author, as there is no readily apparent way to access archived data from the Johns Hopkins University Center for Systems Science Engineering database.

# Materials and procedure

## Computational environment
```{r setup, include = FALSE}
# required packages
packages <- c(
  "tidycensus", "tidyverse", "downloader", "sf", "classInt", "readr",
  "here", "s2", "pastecs", "tmap", "SpatialEpi", "svDialogs",
  "geepack", "knitr", "kableExtra", "foreign", "broom", "dotwhisker", "dotenv"
)

# load and install required packages
if(!require(groundhog)){
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

groundhog.day <- "2025-02-01"

groundhog.library(packages, groundhog.day,
                  tolerate.R.version='4.4.2')
# you may need to...
# install a correct version of R
# install the rstudioapi package with install.packages("rstudioapi")
# respond OK in the console to permit groundhog to install packages
# restart the R session and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# non-groundhog method for installing packages:
# lapply(packages, library, character.only = TRUE)

# save the R processing environment
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# set up default knitr parameters
knitr::opts_chunk$set(
  echo = FALSE,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

## Data transformations and Analysis

### Step 1: Acquire John's Hopkins COVID data

Data on COVID-19 cases from the Johns Hopkins University dashboard have been provided directly with the research compendium because the data is no longer available online in the state in which it was downloaded on August 1, 2020.
The dashboard and cumulative counts of COVID-19 cases and deaths were continually updated, so an exact reproduction required communication with the original author, Jayajit Chakraborty, for assistance with provision of data from August 1, 2020.

The data includes an estimate of the total population (`POP_ESTIMA`) and confirmed COVID-19 cases (`Confirmed`).
The COVID-19 case data expresses cumulative count of reported COVID-19 from 1/22/2020 to 8/1/2020.
Although metadata for this particular resource is no longer available from the original source, one can reasonably assume that the total population estimate was based on the 2014-2018 5-year ACS estimate, as the 2019 estimates data had not been released yet.

Versions of the data can be found at the John Hopkins CCSE COVID-19 Data Repository (<https://github.com/CSSEGISandData/COVID-19>).
However, archived data only provides summaries at the national scale.
We received the COVID-19 case data through 8/1/2020 at the county level from the author, as there is no readily apparent way to access archived data from the Johns Hopkins University Center for Systems Science Engineering database.

#### Load COVID data

```{r load-covid-data}
covid <- read_sf(here("data", "raw", "public", "covidcase080120.gpkg"))

# select and rename the fips code, population, cases, and x,y coordinates
covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x = X, y = Y
)
```

### Step 2: Calculate incident rate by county

Calculate incidence rate (cases per 100,000 people)

Convert the COVID data to a non-geographic data frame.

```{r covid-rate}
covid_table <- covid %>%
  mutate(covid_rate = round(covid$cases / covid$pop * 100000, 2)) %>%
  st_drop_geometry()
```

### Step 3: Acquire ACS data

Examine ACS variables from relevant tables

American Community Survey (ACS) data for sociodemographic subcategories of people with disabilities can be accessed by using the `tidycensus` package to query the Census API. This requires an API key which can be acquired at [api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html).

#### Load ACS variables and query census (if needed)

Create variable csv tables

```{r}
acs_subject_vars <- load_variables(2018, "acs5/subject")
acs_vars_S1810 <- acs_subject_vars |> filter(str_detect(name, "S1810"))
write_csv(acs_vars_S1810, here("data", "metadata", "acs_S1810_vars.csv"))

acs_vars <- load_variables(2018, "acs5")
acs_vars_C18130 <- acs_vars |> filter(str_detect(name, "C18130"))
write_csv(acs_vars_C18130, here("data", "metadata", "acs_C18130_vars.csv"))
```

Query census (don't run if data is already saved)

```{r API-Load-ACS, eval=FALSE}
# If you wish to use a census API key, run the census_api_key() function in the console

# Query disability demographic data with geographic boundaries
acs <- get_acs(
  geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Query poverty and disability data
acs_pov <- get_acs(
  geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

# Query state geographic data
state <- get_acs(
  geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Save query results
saveRDS(acs, here("data", "raw", "public", "acs.RDS"))
saveRDS(acs_pov, here("data", "raw", "public", "acs_pov.RDS"))
saveRDS(state, here("data", "raw", "public", "state.RDS"))
```

#### Load in saved data

```{r load-acs}
acs <- readRDS(here("data", "raw", "public", "acs.RDS"))
acs_pov <- readRDS(here("data", "raw", "public", "acs_pov.RDS"))
state <- readRDS(here("data", "raw", "public", "state.RDS"))
```

#### Transformations

To be consistent with study extent, exclude Alaska, Hawai'i and Puerto Rico from the dataset.

Also, join poverty ACS variable to other ACS data using GEOID to create one dataset with all of the study variables.

Finally, transform the ACS geographic data into Contiguous USA Albers Equal Area projection and fix geometry errors.

Join variables from `acs_vars_S1810` and `acs5_c18130`

```{r filter-join-acs}
# Remove Alaska, Hawaii & Puerto Rico,
# transform coordinate system and fix geometries
acs <- filter(acs, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070) %>%
  st_make_valid()

# Remove Alaska, Hawaii & Puerto Rico,
state <- filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)

# Join poverty data to disability data
acs <- left_join(acs, acs_pov, by = "GEOID")
rm(acs_pov)
```

Calculate independent socio-demographic variables of people with disabilities as percentages for each sub-category of disability (race, ethnicity, poverty, age, and biological sex) and remove raw census data from the data frame (workflow step 4).

Reproject the data into an Albers equal area conic projection.

Number of PwDs / total from each PwD variable * 100

```{r Preprocess-ACS}
# calculate percentages
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct =
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E) / S1810_C01_001E * 100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct =
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100,
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
)

# select only relevant geographic identifiers and derived percentages
acs_derived <- acs_derived %>%
  select(
    fips = GEOID,
    statefp = STATEFP,
    county = NAME.x,
    county_st = NAME,
    contains("pct")
  )
```

### Step 4: Join ACS to COVID data

Join dependent COVID data to independent ACS demographic data.

```{r join-covid-to-acs}
# Join COVID incidence rate data to acs data
acs_covid <- acs_derived %>%
  left_join(covid_table, by = "fips")

# move covid_rate column prior to disability percentages
acs_covid <- acs_covid %>%
  select(fips, statefp, county, county_st, covid_rate, everything())

rm(acs, acs_derived, covid)
```

#### Unplanned deviation for reproduction: County with missing disability and poverty data.

This was not mentioned in the original study or in our pre-analysis plan.
However, we replace the missing data with zeros, producing results identical to Chakraborty's.

```{r missing data}
# county with missing data
filter(acs_covid, is.na(bpov_pct)) %>% st_drop_geometry() %>% kable()
```

Replace the `NA` values with `0`.

```{r replace-na}
acs_covid <- acs_covid %>% replace_na(list(bpov_pct = 0,
                                           apov_pct = 0))
```

### Produce map: COVID incident rate data (compare to Figure 1 in original study)

```{r map-covid-rates, message = FALSE}
tm_covid_rates <- tm_shape(acs_covid) +
  tm_polygons("covid_rate",
    title = "COVID-19 Cases per 100,000 people\n(22 January 2020 to 1 August 2020)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_covid_rates
```

### Unplanned deviation for reproduction: Produce map of spatial distribution of the percent of people with any disability (PwD rates by county) 

The purpose of this step is to improve our understanding of the geographic patterns and relationships of between the overarching independent variable (percentage of people with disability) and the dependent variable (COVID-19 incidence rate).

```{r map-disability-rates, message = FALSE}
tm_disability_rates <- tm_shape(acs_covid) +
  tm_polygons("dis_pct",
    title = "Percent of People with Disability\n(ACS 2014-2018)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Blues"
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_disability_rates
```

### Step 5: `summarise()`

Calculate summary statistics for dependent COVID-19 rate and independent PwD socio-demographic characteristics (Min, Max, Mean, SD) to reproduce columns of original study table 1

```{r descriptive-statistics}
acs_covid_stats <- acs_covid %>%
  st_drop_geometry() %>%
  select(covid_rate, contains("pct")) %>%
  stat.desc(norm = TRUE) %>%
  round(2) %>%
  t() %>%
  as.data.frame() %>%
  select(min, max, mean, SD = std.dev)

acs_covid_stats %>%
  kable(caption = "Reproduced Descriptive Statistics",
        align = "c")
```

### Step 7: Bivariate Pearson product-moment correlations

Correlate `cor()` COVID cases, pct disability for each disability variable

#### `Mutate()` to produce Pearson's r column in Table 1

`mutate( t = abs(r) / sqrt((1 - r\^2) / (df)), p = pt(t, df, lower.tail = FALSE) )`

```{r pearsons-correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  select(r = covid_rate) %>%
  mutate(
    t = abs(r) / sqrt((1 - r^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  dplyr::filter(variable != "covid_rate")

pearsons_r %>%
  kable(caption = "Reproduced Pearson's R",
        align = "c") %>%
  column_spec(2:4, width = "4em") %>%
  kable_styling(full_width = FALSE)
```

### Check results with Table 1

#### Digitize Table 1 from original study

Subtract results from Chakraborty's Table 1

Compare reproduced descriptive statistics to original descriptive statistics.
Difference is calculated as 'reproduction study - original study'.
Identical results will result in zero.

```{r compare-descriptive-stats}
# load original table 1 results
table1 <- read.csv(here("data", "raw", "public", "chakraborty", "table1.csv"))

# subtract original results from reproduced results
(select(acs_covid_stats, min, max, mean, SD) -
  select(table1, min, max, mean, SD)) %>%
  kable(caption = "Descriptive Statistics Comparison",
        align = "c") %>%
  column_spec(2:5, width = "4em") %>%
  kable_styling(full_width = FALSE)

rm(acs_covid_stats)
```

Compare the reproduced Pearson's *r* correlation coefficients to the original study's Pearson's *r* correlation coefficients.
Stars indicates the significance level with two stars for `p < 0.01` and one star for `p < 0.05`.
Correlation difference `rp_r_diff` is calculated between the reproduction study `rp_r` and original study `or_r` as `rp_r_diff = rp_r - or_r` Direction difference `rp_dir_diff` is calculated as `(rp_r > 0) - (or_r > 0)`, giving `0` if both coefficients have the same direction, `1` if the reproduction is positive and the original is negative, and `-1` if the reproduction is negative but the original is positive.

```{r compare-pearsons-correlation}
# calculate number of significance stars at p < 0.01 and p < 0.05 levels.
pearsons_r <- mutate(pearsons_r, rp_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

# join reproduction coefficients to original study coefficients
correlations <- table1 %>%
  filter(variable != "covid_rate") %>%
  select(variable, or_r = r, or_stars = stars) %>%
  left_join(select(pearsons_r, variable, rp_r = r, rp_stars), by = "variable")

# find difference between coefficient and stars
correlations <- correlations %>%
  bind_cols(rename_with(
    correlations[, 4:5] - correlations[, 2:3],
    ~ paste0(.x, "_diff")
  ))

# find coefficients with different directions
correlations <- correlations %>% mutate(rp_dir_diff = (rp_r > 0) - (or_r > 0))

correlations %>%
  kable(caption = "Compare reproduced and original Pearson's R",
        col.names = c("Variable", "R", "Sig. Level", "R", "Sig. Level", "R", "Sig. Level", "Direction"),
        align = "c") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Original" = 2, "Reproduced" = 2, "Difference" = 3))
```

Reproduction correlation coefficients varied slightly from the original study coefficients by +/- 0.006.
All but one Pearson's correlation coefficient was significant to the same level, and the exception was age 18 to 34.
Counter-intuitively, the correlation coefficient was slightly closer to 0 but the *p* value was also found to be more significant, suggesting a difference in the estimation of *t* and/or *p*, or a typographical error.
All of the coefficients had the same direction.

**Unplanned Deviation for Reproduction**: We should expect identical results for this correlation test, so we loaded the original author's data from `Aug1GEEdata.csv` to re-test the statistic, calculated as `unplanned_r` below.

```{r original-data-pearson-correlation}
# load author-provided original data
original_gee <- read.csv(here("data", "raw", "public", "chakraborty", "Aug1GEEdata.csv"))

# calculate correlation coefficients using original data
original_gee %>%
  select(Incidence, PerDisable, starts_with("PD")) %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  rownames_to_column("or_variable") %>%
  filter(or_variable != "Incidence") %>%
  select(or_variable, unplanned_r = Incidence) %>%
  bind_cols(correlations[, 1:2]) %>%
  mutate(unplanned_r = round(unplanned_r, 3), diff = unplanned_r - or_r) %>%
  select(variable, unplanned_r, or_r, diff) %>%
  kable(caption = "Recalculation of Pearson's R with original data",
        align = "c",
        ) %>%
  kable_styling(full_width = FALSE)
```

The author's original data produced coefficients identical to the original publication!
Is it possible that the data values are correct but have been reassigned / transposed to different counties?

*Unplanned Deviation for Reproduction*: Considering the precise bitwise reproduction of descriptive statistics and of correlation statistics from author-provided data, we decided to recalculate the COVID-19 incidence rate with author-provided case and population data for comparison to the author-provided incidence rate.

```{r compare-incidence-rate}
# recalculate Incidence Rate
original_gee <- original_gee %>%
  mutate(recalc_Incidence = round(Cases / Total_POP * 100000, 2))

# compare recalculation to author-provided original data and print any counties
# with inconsistent results
original_gee %>%
  filter(recalc_Incidence != Incidence) %>%
  select(FIPS = COUNTY_FIPS, State = ST_Name, County = Countyname, Population = Total_POP, Cases, OR_Incidence = Incidence, RPr_Incidence = recalc_Incidence) %>%
  mutate(Difference = RPr_Incidence - OR_Incidence) %>%
  kable(caption = "Counties with inconsistent COVID-19 incidence rate") %>%
  kable_styling(latex_options = "scale_down")
```

We found that 13 counties had incorrect COVID-19 incidence scores, and the scores seem to be transposed from other counties, such that the overall descriptive statistics were accurate but the correlation coefficients were inaccurate.
This finding implies that subsequent analyses using the COVID-19 Incidence rate will be slightly different and more accurate in this reproduction study than in the original study.

**Unplanned deviation for reproduction:** Join the original author's Incidence data into our reproduction data frame so that we can later test for sensitivity to this error.
Then report any counties for which the reproduced COVID incidence rate differs from the original author's COVID incidence rate.

```{r join-incidence-rate}
original_incidence <- original_gee %>%
  select(COUNTY_FIPS, or_incidence = Incidence) %>%
  mutate(fips =
           ifelse(COUNTY_FIPS >= 10000,
                  as.character(COUNTY_FIPS),
                  paste0("0", COUNTY_FIPS)
                  )
         )
  # calculates a text version of FIPS code for joining, while adding back
  # the leading '0' if the code was less than 10000

acs_covid <- acs_covid %>%
  left_join(original_incidence, by = "fips")

rm(original_incidence)

acs_covid %>%
  st_drop_geometry %>%
  filter(covid_rate != or_incidence) %>%
  arrange(fips) %>%
  select(county_st, covid_rate, or_incidence) %>%
  kable(caption = "Original incidence rate joined to reproduction data") %>% kable_styling()
```

The join worked, highlighting the same 13 counties with inconsistent incidence rates.
This also confirms that our reproduced dependent variable is identical to the original dependent variable with the exception of these three counties.

## *Planned Deviation*

### Step 8: Kulldorff method with `SpatialEpi` package

First, calculate the Kulldorff spatial scan statistic using SpatialEpi.
Optionally, skip this code block due to long run times of more than 10 minutes.

```{r SpatialEpi-Kulldorff, eval = FALSE, fig.width=4, fig.height=4}
start_time <- Sys.time()
covid_geo <- covid_table %>%
  select(x, y) %>%
  latlong2grid()
# latlong2grid creates approximate equidistant cylindrical grid
# could probably reproject to epsg 5070 and create table with x and y

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases, 1)

# Kulldorff spatial scan statistic
covid_kulldorff <- kulldorff(
  geo = covid_geo,
  cases = covid_table$cases,
  population = covid_table$pop,
  expected.cases = expected.cases,
  pop.upper.bound = 0.5,
  n.simulations = 999,
  alpha.level = 0.05,
  plot = TRUE
)

print(
  paste(
    "Run time:",
    round(difftime(Sys.time(), start_time, units = "mins"), 2),
    "minutes"
  ),
  quote = FALSE
)
rm(covid_geo, expected.cases, start_time)

# save results in a file appended with the current date
saveRDS(covid_kulldorff,
  file = here("data", "derived", "public", paste0("covid_kulldorff_", Sys.Date(), ".RDS"))
)
```

Load pre-calculated Kulldorff results

```{r load-Kulldorff}
# load pre-calculated Kulldorff results
# alternatively, modify the file name with an appended date to load a more current set of results
covid_kulldorff <- readRDS(
  here("data", "derived", "public", "covid_kulldorff_2025-04-08.RDS")
)
```

Report Kulldorff spatial scan results.

```{r report-Kulldorff}
print("Most likely cluster:", quote = FALSE)
covid_kulldorff$most.likely.cluster
print(
  paste0(
    "Number of Secondary clusters: ",
    length(covid_kulldorff$secondary.clusters)
  ),
  quote = FALSE
)
```

Assign unique cluster ID's to each county within a cluster.
Clusters include the county at the center of a cluster and all of the other counties within the cluster radius.
Therefore, we use the FIPS code of the county at the center of each cluster as the unique cluster ID.

```{r assign-cluster-IDs, message = FALSE}
# list of primary cluster locations (counties)
cluster_locations <- covid_kulldorff$most.likely.cluster$location.IDs.included

# create data frame of clusters and
# calculate the clusterID as the first (center) county FIPS code
clusters <- covid_table[cluster_locations, "fips"] %>%
  mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
         likelihood = covid_kulldorff$most.likely.cluster$log.likelihood.ratio)

# Get a list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# similarly add counties in each secondary cluster to the list of clusters
for (i in secondary) {
  cluster_locations <- i$location.IDs.included
  new_clusters <- covid_table[cluster_locations, "fips"] %>%
    mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
           likelihood = i$log.likelihood.ratio)
  clusters <- clusters %>% rbind(new_clusters)
}

rm(cluster_locations, secondary, i, new_clusters)
```

### Map: Spatial Clusters

First, we must join the Kulldorff spatial scan cluster IDs to the acs_covid simple features dataframe.
Although this was planned in workflow step 9, the order of operations between steps 9 and steps 7 and 8 is not important.

Next, calculate a new field `isCluster` to identify counties in COVID-19 clusters.
Additionally, distinguish between counties defining the center of a cluster from counties constituting other parts of a cluster by comparing the cluster ID (equivalent to the center county's fips code) to the county fips code.

```{r join-clusterID-to-acs_covid}
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "or_incidence")] %>%
  left_join(clusters, by = "fips") %>%
  mutate(isCluster = case_when(
    clusterID == fips ~ "center of cluster",
    !is.na(clusterID) ~ "other part of cluster",
    .default = NA
  ))
```

```{r map-clusters}
tm_spatialepi_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "isCluster",
          palette = "-Oranges",
          popup.vars = c("fips", "clusterID"),
          value.na = NULL,
          title = "SpatialEpi Kulldorff COVID-19 Clusters",
          border.col = "white",
          lwd = 0.2,
          border.alpha = 0.2) +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_clusters
```

### Step 9: Calculate relative risk

`(local cases/local population) / (global cases - local cases/global population - local population)`

Classify counties using `mutate(case_when())`

The `SpatialEpi` implementation of Kulldorff spatial scan statistics does not calculate local relative risk or cluster relative risk.
Therefore, the next step is to calculate local and cluster relative risk (workflow step 7).

```{r relative-risk}
total_pop <- sum(acs_covid$pop)
total_cases <- sum(acs_covid$cases)

acs_covid <- acs_covid %>%
  group_by(clusterID) %>%
  mutate(
    rr_cluster = ifelse(is.na(clusterID), NA,
      (sum(cases) / sum(pop)) / ((total_cases - sum(cases)) / (total_pop - sum(pop)))
    )
  ) %>%
  ungroup() %>%
  mutate(
    rr_loc = (cases / pop) / ((total_cases - cases) / (total_pop - pop))
  )

rm(total_pop, total_cases)
```

Classify relative risk on a scale from 1 to 6 (workflow step 8).
Risk is classified according to this table:

| Relative Risk Values | Relative Risk Class |
|:--------------------:|:-------------------:|
|  Outside of cluster  |          1          |
|       RR \< 1        |          1          |
|    1 \<= RR \< 2     |          2          |
|    2 \<= RR \< 3     |          3          |
|    3 \<= RR \< 4     |          4          |
|    4 \<= RR \< 5     |          5          |
|    5 \<= RR \< 6     |          6          |

Counties falling outside of any cluster are assigned a score of 1.

```{r classify-relative-risk}
# class breaks
breaks <- c(-Inf, 1, 2, 3, 4, 5, Inf)

acs_covid <- acs_covid %>%
  mutate(
    cluster_class = ifelse(is.na(clusterID), 1, cut(rr_cluster, breaks, labels = FALSE)),
    loc_class = cut(rr_loc, breaks, labels = FALSE)
  )
```

### Step 10: Concatenate

`c(state + relative risk)` to produce unique cluster identification codes

The original study did not directly report any results from the Kulldorff spatial scan statistic.
However, the Kulldorff cluster relative risk scores were combined with states to create clusters for GEE models, hereafter called "GEE clusters".
The original study reported `102` unique GEE clusters having a range of `1` to `245` counties in each cluster.

In order to compare results, we first create cluster IDs as combinations of the state ID and COVID relative risk class.
The first clustering ID (State) and second clustering score (COVID relative risk class) were combined to form IDs for each unique combination of state and relative risk class.
Then, we find the number of unique clusters and frequency counties per cluster in our reproduction study for comparison to the original study.

```{r make-gee-clusters}
# calculate clusters
acs_covid <- acs_covid %>% mutate(
  rp_clusID = as.integer(statefp) * 10 + cluster_class
)
```

### Check number of clusters - compare to total of 102 in original study

```{r}
# summarize clustering results
cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(rp_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
rm(cluster_summary)
```

We failed to reproduce the same configuration of GEE clusters as the original study, finding 9 more clusters than the original study and a much smaller maximum cluster of 159 counties compared to 245 counties.

### Map: Qualitative map of clusters

Reproduce Kulldorff spatial scan statistic in SaTScan

**Unplanned deviation for reproduction**: Upon failing to reproduce an identical number of GEE clusters using SpatialEpi in R, we reproduced the procedure in the free but not open SaTScan software, using the current software version 10.1.
The input data files (`case`, `Coordinates.geo`, and `Population.pop`), and output data files (`sat_scan_rpr.txt`, `sat_scan_rpr.col.shp`, and `sat_scan_rpr.gis.shp`) are found in the `data/derived/public/satscan` directory.
The `sat_scan_rpr.txt` file reports the model parameters used in addition to results.

Although it is not ideal to intercede with this unplanned deviation at this step, is the first step in the methodology following the Kulldorff spatial scan statistic with a result reported in the original publication.

First, load and verify whether our SaTScan reproduction data compares to the author-provided SaTScan data.

```{r load-satscan-col}
# load author-provided data
author_col <- read.dbf(here("data", "raw", "public", "chakraborty", "SatScan_output.dbf")) %>%
  select(LOC_ID, or_rel_risk = REL_RISK)

# load SaTScan reproduced data
satscan_rpr_col <- read_sf(here("data", "derived", "public", "satscan", "sat_scan_rpr.col.shp"))

# how many observations?
cat(
  nrow(satscan_rpr_col),
  " reproduced relative risk observations\n",
  nrow(author_col),
  " author-provided relative risk observations\n",
  sep = ""
)

# join and compare how many observations are identical?
cat(
  satscan_rpr_col %>%
  full_join(author_col, by = "LOC_ID") %>%
  filter(REL_RISK == or_rel_risk & REL_RISK > 0) %>%
  nrow(),
  "reproduced relative risk values match the original author's relative risk values"
  )

rm(author_col)
```

Our SaTScan results exactly reproduced the author-provided SaTScan results data.

#### Map SaTScan spatial clusters

Join the SaTScan results to `acs_covid` for mapping and analysis.

```{r join-satscan-to-acs-covid}
# check if there are any duplicated counties
cat("Joining",
    length(satscan_rpr_col$LOC_ID),
    "records with",
    length(unique(satscan_rpr_col$LOC_ID)),
    "unique LOC_ID county values")

# select important non-geographic columns
satscan_rpr_col_t <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, GINI_CLUST, REL_RISK)

# join
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "rp_clusID")] %>%
  left_join(satscan_rpr_col_t, by = "fips")

rm(satscan_rpr_col_t)
```

**Unplanned deviation for reproduction**: Visualize the spatial distribution of the author-provided Kulldorff COVID-19 Clusters.

```{r map--author-clusters}
# count frequencies of each cluster type
clus_counts <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  group_by(GINI_CLUST) %>%
  summarize(n = n())

# create labels including frequencies in brackets
clus_labels <- c(paste0("Hierarchical (", clus_counts[1,2], ")"),
            paste0("GINI Optimized (", clus_counts[2,2], ")"))

# for clusters with only one county, erase the number of counties
satscan_rpr_col[which(satscan_rpr_col$NUMBER_LOC < 3), ]$NUMBER_LOC <- NA

gini_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'T')
hier_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'F')

tm_author_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "GINI_CLUST",
              fill.scale = clus_labels,
              border.col = "white",
              lwd = 0.5,
              values = c("tomato", "thistle3"),
              popup.vars = c("fips", "clusterID"),
              value.na = NULL,
              title = "SaTScan Kulldorff COVID-19 Clusters\nCluster Centers") +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_shape(gini_circle) +
    tm_borders(col = "thistle4") +
   # tm_text("NUMBER_LOC", size = 0.5) +
  tm_shape(hier_circle) +
    tm_borders(col = "tomato") +
   # tm_text("NUMBER_LOC", size = 0.5, ymod = 0.4) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  ) +
  tm_add_legend('symbol',
              	col = NA,
              	border.col = c("tomato", "thistle4"),
              	size = 0.7,
              	labels = clus_labels,
              	title="Cluster Extents")

tm_author_clusters

rm(gini_circle, hier_circle, clus_counts, clus_labels)
```

In the map above, clusters containing only one county have no visible circle.
Clusters containing two counties are encircled, but have no label.
Clusters containing three or more counties are encircled and labelled with the number of counties.

Note that this version of data only includes the 96 counties defining cluster centers, visualized with fill colors above.
The data excludes all of the non-center counties in clusters with more than one county.
The extent of these larger clusters is visualized by unfilled circles defined by cluster radii.

### Step 11: Compare data with GEE results (`Aug1GEE`)

The generalized estimating equation (GEE) models were used to test association between intra-categorical rates of disability and COVID-19 incidence rates while accounting for spatial clustering.
A separate hypothesis was formulated for each type of subcategorization of PwDs, numbered H2.1 through H2.5 in Table 4.

As specified by the author, "GEEs extend the generalized linear model to accommodate clustered data, in addition to relaxing several assumptions of traditional regression (i.e., normality)".
Additionally, the author noted that "clusters of observations must be defined based on the assumption that observations within a cluster are correlated while observations from different clusters are independent." All five GEE models were specified with exchangeable correlation matrices, gamma distributions, and logarithmic link function.
These specifications were chosen after testing each alternative and choosing the models with the best quasilikelihood under the independence model criterion (QIC).

This accomplishes the step 11 of the workflow diagram.

#### Preprocess data for GEE modelling

**Unplanned deviation for reanalysis**: Based on the three observations above, we think that it would be more valid to choose one set of secondary clusters based on a single method rather than combining a set of hierarchical clusters with a set of GINI optimized clusters.
We also think that it would be more valid to include risk levels for all counties within a cluster (i.e. all counties within any of the circles above), rather than only the county at the center of a cluster.
Finally, we think it would be more valid to treat clusters as a single category rather than five tiers of above-normal risk.

To complete the reproduction/reanalysis study, we will therefore calculate and compare multiple versions of the GEE models:

1.  Original study results
2.  Original study data in geepack
3.  SpatialEpi cluster classification in geepack
4.  SpatialEpi binary clusters in geepack

### Unique GEE cluster IDs

First, calculate GEE cluster IDs.

We have already calculated: - `rp_clusID` based on our SpatialEpi clusters - `ss_clusID` based on our SaTScan cluster centers, and shown to be identical to the original author's data - `gini_clusID` based on our SaTScan GINI-optimized clusters

### Filter and standardize data

Second, filter the data for non-zero COVID-19 rates and z-score standardize the independent variables.
This accomplishes step 10 of the workflow diagram.

**Unplanned deviation for reproduction:** We assumed that we should filter for COVID rates \> 0 first and then calculate z-scores, however after comparing data in the next code block, we realized that the original study had *first* calculated z-scores and *then* filtered for COVID rates \> 0.
Therefore, to align with the original study, in the next code block we first calculate z-scores and then filter for COVID rates \> 0.

```{r filter-standardize}
gee_data <- acs_covid %>%
# filter(covid_rate > 0) %>% # moved filtering to after z-score calculation
  mutate(
    z_white_pct = scale(white_pct),
    z_black_pct = scale(black_pct),
    z_native_pct = scale(native_pct),
    z_asian_pct = scale(asian_pct),
    z_other_pct = scale(other_pct),
    z_non_hisp_white_pct = scale(non_hisp_white_pct),
    z_hisp_pct = scale(hisp_pct),
    z_non_hisp_non_white_pct = scale(non_hisp_non_white_pct),
    z_bpov_pct = scale(bpov_pct),
    z_apov_pct = scale(apov_pct),
    z_pct_5_17 = scale(pct_5_17),
    z_pct_18_34 = scale(pct_18_34),
    z_pct_35_64 = scale(pct_35_64),
    z_pct_65_74 = scale(pct_65_74),
    z_pct_75 = scale(pct_75),
    z_male_pct = scale(male_pct),
    z_female_pct = scale(female_pct)
  ) %>%  
  filter(covid_rate > 0) # moved filtering from before z-score calculation
```

Compare independent variables for GEE models by subtracting the original values from the reproduced values, and finding the average and standard deviation of difference for each variable.

```{r compare-indp-vars}
# subtract original data matrix (table) from reproduced data matrix (table)
# select, filter, and arrange (sort) data to make identical matrix sizes with
# identical order of observations (counties)
gee_diff <-
  (gee_data %>%
    st_drop_geometry() %>%  
    arrange(as.integer(fips)) %>%
    select(starts_with("z_"))  -
  original_gee %>%
    filter(Cases > 0) %>%
    arrange(COUNTY_FIPS) %>%
    select(starts_with("ZPD"))) %>%
  round(digits = 3)

# print results
# this would be better as a table
cat("Summary of difference between reproduction independent variables and original independent variables")
cat("\n")
cat("Mean:\n")
colMeans(gee_diff) %>% round(digits = 3)
cat("\nStandard deviation:\n")
apply(gee_diff, 2, sd) %>% round(digits = 3)
```

When we had filtered for COVID rates \> 0 first and then z-score standardized second, the means of differences ranged from -0.012 to 0.004, and standard deviations of differences ranged from 0.000 to 0.016.

After changing the order to first z-score standardize and then filter for COVID rates \> 0, we observed no mean difference between our reproduced variables and the original variables, and we find no standard deviation \> 0.001 for the difference between reproduction independent variables and original variables.
There are no major differences between the independent variables.

#### Save final derived data

Optionally, you may save the preprocessed data to `data/raw/public/gee_data.gpkg`

```{r save preprocessed COVID cluster data, eval = FALSE}
write_sf(gee_data, here("data", "derived", "public", "gee_data.gpkg"))
# add saving acs_covid data
```

Optionally, you may load the preprocessed data from `data/raw/public/gee_data.gpkg`

```{r load preprocessed COVID cluster data, eval = FALSE}
gee_data <- read_sf(here("data", "derived", "public", "gee_data.gpkg"))
```

Generalized Estimating Equation parameters:

"The **'exchangeable' correlation matrix** was selected for the results reported here, since this specification yielded the best statistical fit based on the QIC (quasi- likelihood under the independence) model criterion." (Chakraborty 2021, Methods paragraph 5)

"The **gamma distribution** with **logarithmic link function** was chosen for all GEEs since this model specification provided the lowest QIC value." (Chakraborty 2021, Methods paragraph 5)

### Original Table 2

Load digitized version of Table 2 from the original publication.

```{r load-table2}
table2 <- read.csv(here("data", "raw", "public", "chakraborty", "table2.csv"))
table2 <- table2 %>%
  arrange(row_i_first) #%>%
  #column_to_rownames("term")

table2[, 3:ncol(table2)] %>%
  kable(caption = "Original Publication Table 2",
        align = "c") %>%
  kable_styling()
```

### GEE Function

Define a function for calculating and summarizing five GEE models

```{r gee-functions}
onegee <- function(gee_data, dep_var, id, term_names) {

  # sort data frame by clustering variable, a requirement of GEE modeling
  gee_data <- gee_data %>% arrange({{ id }})

  # create list of models and their independent variables
  model_names <- c(
    "race",
    "ethnicity",
    "poverty status",
    "age",
    "biological sex"
  )

  ind_vars <- c(
    "z_white_pct + z_black_pct + z_native_pct + z_asian_pct + z_other_pct",
    "z_non_hisp_white_pct + z_hisp_pct + z_non_hisp_non_white_pct",
    "z_bpov_pct + z_apov_pct",
    "z_pct_5_17 + z_pct_18_34 + z_pct_35_64 + z_pct_65_74 + z_pct_75",
    "z_male_pct + z_female_pct"
  )

  gee_models <- data.frame(model_names, ind_vars)
  gee_model <- list()

  # empty data frame for storing model outputs
  coefficients <- data.frame()
  qics <- data.frame(model_names, qic = c(1:5))

  # run each model and save outputs
  for(i in 1:nrow(gee_models)){

    # run model
    gee_model[[i]] <- geeglm(
      formula = as.formula(paste(dep_var, "~", gee_models[i, "ind_vars"])),
      data = gee_data,
      id = {{ id }}, # cluster IDs
      family = Gamma(link = "log"),
      corstr = "exchangeable",
    )

    # tidy and save variable coefficients, margins of error, significance...
    gee_table <- tidy(gee_model[[i]], conf.int = TRUE)
    gee_table[1, 1] <- paste(gee_models[i, 1], "model intercept")
    coefficients <- coefficients %>% rbind(gee_table)

    # QIC: quasi-likelihood under the independence model information criterion
    QIC(gee_model[[i]])
    qics[i, 2] <- QIC(gee_model[[i]])[1]

    gee_model[[i]]$model <- NA
  }

  # calculate significance levels
  coefficients$stars <- as.numeric(
    as.character(
      cut(coefficients$p.value,
        breaks = c(-0.1, 0.01, 0.05, 1),
        labels = c(2, 1, 0)
      )
    )
  )

  # reorder columns to match table2 in publication and round to 3 sig. digits
  coefficients <- coefficients %>%
    select("estimate", "std.error", starts_with("conf"), "stars", "p.value") %>%
    round(digits = 3)

  # add tidy term names
  coefficients <- bind_cols(term = term_names, coefficients)

  # combine coefficient results and QIC results into a list
  return_data <- list(
    "coefficients" = coefficients,
    "QICs" = qics,
    "models" = gee_model
    )

  return(return_data)
}
```

### SpatialEpi Clusters and Fixed COVID-19 Rate

Calculate GEE models with: - Clustering: Reproduced SpatialEpi clusters & State ID - Dependent variable: reproduced COVID-19 incidence (fixed errors).

```{r gee-spatialepi-clusters-reproduced-incidence}
gee_rp_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$rp_clusID,
                    term_names = table2$term)
gee_rp_clus_rpdep$coefficients %>%
  kable(caption = "Reproduced SpatialEpi Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

# Results

Present maps, takeaways from comparing data with original study results.

create map of original clusters versus reproduction clusters side by side

# Discussion

Explain weaknesses in original study design/data, points for improvement.

# Acknowledgements

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, [DOI:[10.17605/OSF.IO/W29MQ](DOI:%5B10.17605/OSF.IO/W29MQ){.uri}](https://doi.org/10.17605/OSF.IO/W29MQ)

# References
[github.com/HEGSRR/RPr-Chakraborty2021](https://github.com/HEGSRR/RPr-Chakraborty2021)